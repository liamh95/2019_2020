\documentclass[11pt,letterpaper]{report}
\usepackage{amssymb,amsfonts,color,graphicx,amsmath,enumerate}
\usepackage{tikz}
\usepackage{amsthm}
\usepackage{bbm}
\usepackage{hyperref}

\newcommand{\naturals}{\mathbb{N}}
\newcommand{\integers}{\mathbb{Z}}
\newcommand{\complex}{\mathbb{C}}
\newcommand{\reals}{\mathbb{R}}
\newcommand{\mcal}[1]{\mathcal{#1}}
\newcommand{\rationals}{\mathbb{Q}}
\newcommand{\Lp}[2]{\left\|{#1}\right\|_{L^{#2}}}
\newcommand{\field}{\mathbb{F}}
\newcommand{\affine}{\mathbb{A}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Prob}{\mathbb{P}}
\newcommand{\Var}{\text{Var}}
\newcommand{\ind}{\mathbbm{1}}
\newcommand{\Cov}{\text{Cov}}

\newenvironment{solution}
{\begin{proof}[Solution]}
{\end{proof}}

\voffset=-3cm
\hoffset=-2.25cm
\textheight=24cm
\textwidth=17.25cm
\addtolength{\jot}{8pt}
\linespread{1.3}

\begin{document}
\noindent{\em Liam Hardiman\hfill{March 18, 2020} }
\begin{center}
{\bf \Large 270B - Homework 4}
\vspace{0.2cm}
\hrule
\end{center}

\noindent\textbf{Problem 1. }
Let $(X_n)$ be an irreducible recurrent Markov chain with doubly-infinite transition matrix $P$. Let $\psi: \naturals\to \naturals$ be a bounded function satisfying
\[
\sum_{j=1}^\infty P_{ij}\psi(j) = \psi(i)\quad\text{for all }i\in \naturals.
\]
Show that $\psi$ is a constant function.
\begin{proof}
	First we claim that $\psi(X_n)$ is a martingale. Let $\mcal{F}_n$ be the filtration generated by $X_1, \ldots, X_n$. We then have by hypothesis
	\[
	\E[\psi(X_{n+1})|\mcal{F}_n] = \sum_{j}P_{X_n, j}\psi(j) = \psi(X_n),
	\]
	so $\psi(X_n)$ is a martingale with respect to this filtration. We showed on a previous homework assignment that bounded martingales converge almost surely, so $\psi(X_n)\to s$ almost surely for some $s\in \naturals$.\\

	\noindent Suppose $\psi$ is non-constant, so $\psi(i) = u$ and $\psi(j) = v$ for some $i\neq j$, $u\neq v$. Intuitively, since the Markov chain is irreducible and recurrent, it should return to states $i$ and $j$ infinitely often with probability 1. But since $\psi(i)\neq \psi(j)$, this means that $\psi(X_n)$ cannot converge almost surely. 
\end{proof}

\noindent\textbf{Problem 2. }
Let $S$ and $T$ be stopping times with respect to a filtration $(\mcal{F}_n)$. Denote by $(\mcal{F}_T)$ the collection of events $F$ such that $F\cap \{T\leq n\} \in \mcal{F}_n$ for all $n$.
\begin{enumerate}[(a)]
	\item Show that $\mcal{F}_T$ is a $\sigma$-algebra.
	\begin{proof}
		That $\emptyset$ and $\Omega$ are in $\mcal{F}_T$ immediately follows from $T$ being a stopping time. To show closure under complementation, write $F\in \mcal{F}_T$ like so
		\[
		F = (F\cap \{T\leq n\})\cup (F\cap \{T>n\}).
		\]
		This gives
		\[
		F^c\cap \{T\leq n\} = (F\cap \{T\leq n\})^c\cap (F\cap \{T>n\})^c\cap \{T\leq n\}.
		\]
		Since $F\cap \{T\leq n\}$ is in $\mcal{F}_n$, the above set is also in $\mcal{F}_n$.\\

		\noindent As for countable unions, let $F_1, F_2, \ldots \in \mcal{F}_T$. Then
		\[
		\left(\bigcup_{k=1}^\infty F_k\right)\cap \{T\leq n\} = \bigcup_{k=1}^\infty (F_k\cap \{T\leq n\}).
		\]
		Since $F_k\cap \{T\leq n\}\in \mcal{F}_n$ for all $n$, the above set is in $\mcal{F}_n$.
	\end{proof}

	\item Show that $T$ is measurable with respect to $\mcal{F}_T$.
	\begin{proof}
		$T$ is measurable with respect to $\mcal{F}_T$ if and only if $\{T\leq n\}\in \mcal{F}_T$ for all $n$. This follows immediately from the fact that $T$ is a stopping time with respect to the filtration $\mcal{F}_n$. 
	\end{proof}

	\item If $E\in \mcal{F}_S$, show that $E\cap \{S\leq T\}\in \mcal{F}_T$.
	\begin{proof}
		The idea is to write $\{S\leq T\}$ as $\cup_{k=1}^\infty \{T = k\}\cap \{S\leq k\}$. For any $E\in \mcal{F}_S$ we then have
		\begin{align*}
		(E\cap \{S\leq T\})\cap \{T\leq n\} &= \bigcup_{k=1}^\infty( E\cap \{S\leq k\}\cap \{T = k\}\cap\{T\leq n\} )\\
		&= \bigcup_{k=1}^n(E\cap \{S\leq k\}\cap \{T = k\}).
		\end{align*}
		Since $E\in \mcal{F}_S$, $E\cap \{S\leq k\}\in \mcal{F}_k$ for all $k$. Since $T$ is a stopping time with respect to $\mcal{F}_n$, $\{T = k\}\in \mcal{F}_k$ for all $k$. Consequently, the above union is in $\mcal{F}_n$, so $E\cap \{S\leq T\}\in \mcal{F}_T$.
	\end{proof}

	\item Show that if $S\leq T$ a.s. then $\mcal{F}_S\subset \mcal{F}_T$.
	\begin{proof}
		Suppose $F\in \mcal{F}_S$. We then have
		\[
		F\cap \{T\leq n\} = (F\cap \{S\leq n\})\cap \{T\leq n\} \in \mcal{F}_n,
		\]
		so $F\in \mcal{F}_T$.
	\end{proof}
\end{enumerate}

\noindent\textbf{Problem 3. }
Let $(X_n)$ be a uniformly bounded [integrable, right?] martingale with respect to the filtration $(\mcal{F}_n)$. Let $S$ and $T$ be two stopping times satisfying $S\leq T$ a.s. Prove that
\[
X_T = \E[X|\mcal{F}_T]\quad\text{and}\quad X_S = \E[X_T|\mcal{F}_S]
\]
where $X$ is the almost sure limit of $X_n$.
\begin{proof}
	Since $X_n$ is uniformly integrable, we can reconstruct $X_n$ from its a.s. (and $L^1$) limit:
	\[
	X_n = \E[X|\mcal{F}_n].
	\]
	Now for any $F\in \mcal{F}_T$ we have $F\cap \{T=n\} \in \mcal{F}_n$ for all $n$.
	\[
	\int_FX_T\ d\Prob = \sum_{n=0}^\infty\int_{F\cap \{T=n\}}X_T\ d\Prob = \sum_{n=0}^\infty \int_{F\cap \{T = n\}}X_n\ d\Prob.
	\]
	By the definition of conditional expectation, the last integral above is equal to
	\[
	\sum_{n=1}^\infty\int_{F\cap \{T = n\}}X\ d\Prob = \int_FX\ d\Prob.
	\]
	Again, by the definition of conditional expectation, we have $X_T = \E[X|\mcal{F}_T]$.\\

	\noindent By problem 2(d), we have that since $S\leq T$ a.s., $\mcal{F}_S\subset \mcal{F}_T$. Consequently, we have by the law of total expectation
	\[
	\E[X_T|\mcal{F}_S] = \E[\E[X|\mcal{F}_T]\ |\ \mcal{F}_S] = \E[X|\mcal{F}_S] = X_S.
	\]
\end{proof}

\noindent\textbf{Problem 4. }
A die is rolled repeatedly. Which of the following are Markov chains? For those that are, compute the transition matrix.
\begin{enumerate}[(a)]
	\item The largest number $X_n$ shown up to the $n$-th roll.
	\begin{solution}
		Intuitively, this should be a Markov chain: to check if the current roll is the largest thus far, we need only compare it to the largest roll seen before. More concretely, consider $1\leq i_1, i_2,  \ldots, i_n\leq 6$. Then
		\[
		\Prob[X_{n+1} = i_{n+1}\ |\ X_n = i_n, \ldots, X_1 = i_1] = \begin{cases}
			i_n/6&\text{if }i_{n+1} = i_n\\
			1/6&\text{if }i_{n+1} > i_n\\
			0&\text{otherwise}
		\end{cases} = \Prob[X_{n+1} = i_{n+1}\ |\ X_n = i_n].
		\]
		The state space of this Markov chain is $\{1, 2, 3, 4, 5, 6\}$ and the transition matrix $P_{i,j}$ is given by
		\[
		P_{i,j}= \begin{cases}
			i/6&\text{if }j = i\\
			1/6&\text{if }j > i\\
			0&\text{otherwise}
		\end{cases}
		\]
	\end{solution}

	\item The number $N_n$ of sixes in $n$ rolls.
	\begin{solution}
		$N_n$ is a Markov chain: the number of sixes on the $n+1$-st roll will either be the same as or one greater than the number of sixes on the $n$-th roll. $N_{n+1}$ will only depend on $N_n$ since the dice rolls are independent. The state space is the set of nonnegative integers and the transition matrix is given by
		\[
		P_{i,j} = \begin{cases}
			5/6&\text{if }j = i\\
			1/6&\text{if }j = i+1\\
			0&\text{otherwise}
		\end{cases}.
		\]
	\end{solution}

	\item At time $r$, the time $C_r$ since the most recent six.
	\begin{solution}
		If $E_n$ is the even that the $n$-th roll is a six, then we have $C_{n+1} = C_n + \ind_{E_{n+1}}$. Since the $(n+1)$-st roll is independent of the previous states of the process, we see that $C_n$ is a Markov chain. The state space is the set of nonnegative integers and its transition matrix is given by
		\[
		P_{i,j} = \begin{cases}
			1/6&\text{if }j = i+1\\
			5/6&\text{if }j = i\\
			0&\text{otherwise}
		\end{cases}.
		\]
	\end{solution}

	\item At time $r$, the time $B_r$ until the next six.
	\begin{solution}
		If $B_r > 1$, then $B_{r+1} = B_r - 1$ almost surely - if the next six will come in $B_r>1$ rolls, then on the next roll it will come in $B_r-1$ rolls. Now if $B_r  = 1$, then the process ``restarts'' and the time until the next six will follow a geometric distribution with parameter $1/6$, i.e. $\Prob[B_{r+1} = j] = \frac{1}{6}(\frac{5}{6})^{j-1}$. In either case, the distribution of $B_{r+1}$ depends only on the value of $B_r$ and we have a Markov chain. The transition matrix is given by
		\[
		P_{i,j} = \begin{cases}
			1&\text{if }i>1,\ j = i-1\\
			\frac{1}{6}(\frac{5}{6})^{j-1}&\text{if }i=1,\ j\geq 1\\
			0&\text{otherwise}
		\end{cases}.
		\]
	\end{solution}
\end{enumerate}

\noindent\textbf{Problem 5. }
Let $S_n$ be a simple random walk starting at $S_0 = 0$. Show that $X_n = |S_n|$ is a Markov chain.
\begin{proof}
	If $|S_n| = i_n$, then $S_n = i_n$ or $S_n = -i_n$. We then have for $i_n > 0$
	\begin{align*}
	\Prob[|S_{n+1}| = i_{n+1}\ |\ |S_n| = i_n, \ldots, |S_1|=i_1]&= \Prob[S_{n+1} = i_{n+1}\ |\ S_n = i_n, \ldots, |S_1|=i_1]\\
	&+\Prob[S_{n+1}=-i_{n+1}\ |\ S_n = -i_n, \ldots, |S_1|=i_1]
	\end{align*}
\end{proof}

\noindent\textbf{Problem 6. }
Let $(X_n)$ be a Markov chain, and let $T$ be a stopping time with respect to the filtration $\mcal{F}_n = \sigma(X_1, \ldots, X_n)$. Show that
\[
\Prob[X_{T+1}=j\ |\ X_k = x_k\text{ for }0\leq k<T,\ X_T = i] = \Prob[X_{T+1}=j\ |\ X_T=i]
\]
for all $m\geq 0$ $i,j$ and $x_k$.
\begin{proof}
	For ease of notation, let $E_m = \{X_k = x_k$ for $0\leq k\leq m\}$. We then have
	\begin{equation}\label{sum}
	\Prob[X_{T+1} = j\ |\ E_T]= \sum_{n=1}^\infty\Prob[X_{T+1}=j\ |\ E_T,\ T=n]\cdot\Prob[T=n\ |\ E_T].
	\end{equation}
	By the definition of conditional probability we have
	\[
	\Prob[X_{T+1}=j\ |\ E_T,\ T=n] = \frac{\Prob[X_{T+1}=j,\ E_T,\ T=n]}{\Prob[E_T,\ T=n]} = \frac{\Prob[X_{n+1}=j,\ E_n,\ T=n]}{\Prob[E_n,\ T=n]}.
	\]
	Now since $T$ is a stopping time, it is $\mcal{F}_n$ measurable. I want to say that $E_n\cap \{T=n\} = E_n$. This gives, by the Markov property
	\[
	\Prob[X_{T+1}=j\ |\ E_T,\ T=n] = \frac{\Prob[X_{n+1}=j, E_n]}{\Prob[E_n]} = \Prob[X_{n+1}=j\ |\ E_n] = \Prob[X_{n+1}=j\ |\ X_n = i_n].
	\]
	Combining this with (\ref{sum}), and using the presumed stationarity of the chain, we have
	\[
	\Prob[X_{T+1} =j\ |\ E_T] = \Prob[X_{n+1}=j\ |\ X_n = i_n] = \Prob[X_{T+1}=j\ |\ X_T=i_T].
	\]
\end{proof}

\noindent\textbf{Problem 7. }
Find an example of two Markov chains $(X_n)$ and $(Y_n)$ such that $X_n+Y_n$ is not a Markov chain.
\begin{solution}
	Let $X_n$ be a simple symmetric random walk on $\integers$ that starts at the origin and let $Y_n$ be given by
	\[
	Y_n = \begin{cases}
		1&\text{if }X_1 = 1\\
		0&\text{if }X_1 = -1
	\end{cases}.
	\]
	We've established that $X_n$ is a Markov chain. Since $Y_n$ is constant, it is also a Markov chain. However, we claim that $Z_n = X_n+Y_n$ is not a Markov chain. Intuitively, the steps $Z_n$ can take to get to $Z_{n+1}$ depend on the first step, $Z_0$. Concretely, consider $\Prob[Z_5 = 3\ |\ Z_4 = 2]$. $Z_4$ could've reached 2 in several different ways, e.g.: $-1, +1, +1, +1$ or $+2,0, 0, 0$. If $Z_1 = -1$, then the probability that $Z_5=3$ is $1/2$. On the other hand, if $Z_1 = 2$, then the probability that $Z_5 = 3$ is $0$.
\end{solution}

\noindent\textbf{Problem 8. }
A particle performs a random walk on the vertices of a three-dimensional cube. At each step it remains where it is with probability 1/4 or moves to one of its neighboring vertices each having probability 1/4. Compute the mean number of steps until the particle returns to the vertex from which the walk started.
\begin{solution}
	Suppose that the particle starts at vertex $u$. Let $\mu_u$ be the expected return time. At each step the particle can stay put with positive probability, so the Markov chain is aperiodic. Furthermore, the cube is connected and finite, so the Markov chain is also irreducible. This chain then admits a stationary distribution $\pi$. We also know that $\mu_u = \frac{1}{\pi_u}$. The uniform measure $\pi_u = \frac{1}{8}$ satisfies the detailed balance equations: for $u$ and $v$ adjacent (note that $u$ is adjacent to itself here)
	\[
		\pi_uP_{u,v} = \pi_vP_{v,u} \iff \frac{1}{8}\cdot \frac{1}{4} = \frac{1}{8}\cdot \frac{1}{4}.
	\]
	We conclude that the mean number of steps until the particle returns to its starting location is 8.
\end{solution}

\noindent\textbf{Problem 9. }
Prove that the symmetric random walk on $\integers^2$ is recurrent while the symmetric random walk on $\integers^3$ is transient.
\begin{proof}
	
\end{proof}

\end{document}