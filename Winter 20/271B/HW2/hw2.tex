\documentclass[11pt,letterpaper]{report}
\usepackage{amssymb,amsfonts,color,graphicx,amsmath,enumerate}
\usepackage{tikz}
\usepackage{amsthm}
\usepackage{bbm}
\usepackage{hyperref}

\newcommand{\naturals}{\mathbb{N}}
\newcommand{\integers}{\mathbb{Z}}
\newcommand{\complex}{\mathbb{C}}
\newcommand{\reals}{\mathbb{R}}
\newcommand{\mcal}[1]{\mathcal{#1}}
\newcommand{\rationals}{\mathbb{Q}}
\newcommand{\Lp}[2]{\left\|{#1}\right\|_{L^{#2}}}
\newcommand{\field}{\mathbb{F}}
\newcommand{\affine}{\mathbb{A}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Prob}{\mathbb{P}}
\newcommand{\Var}{\text{Var}}
\newcommand{\ind}{\mathbbm{1}}
\newcommand{\Cov}{\text{Cov}}

\newenvironment{solution}
{\begin{proof}[Solution]}
{\end{proof}}

\voffset=-3cm
\hoffset=-2.25cm
\textheight=24cm
\textwidth=17.25cm
\addtolength{\jot}{8pt}
\linespread{1.3}

\begin{document}
\noindent{\em Liam Hardiman\hfill{February 20, 2020} }
\begin{center}
{\bf \Large 271B - Homework 2}
\vspace{0.2cm}
\hrule
\end{center}

\noindent\textbf{Problem 1. }
Let $S$, $T$, and $T_n$, $n = 1, 2, \ldots$ be stopping times (with respect to some filtration $\{\mcal{F}_t\}_{t\geq 0}$). Show that $T\lor S$, $T\land S$, $T+S$, $\sup_n T_n$ are also stopping times.
\begin{proof}
	The pointwise minimum, maximum, sum, and supremum of measurable functions are measurable. For the minimum and maximum we have
	\begin{align*}
		\{(T\land S) \leq t\} &= \{T\leq t\} \cup \{S\leq t\}\\
		\{(T\lor S) \leq t\} &= \{T\leq t\} \cap \{S\leq t\}.
	\end{align*}
	Unions and intersections of measurable sets are measurable, so both of these sets live in $\mcal{F}_t$. Thus, $T\land S$ and $T\lor S$ are stopping times. For the sum, we can write the set $\{T+S \leq t\}$ as a countable union:
	\[
	\{T+S \leq t\} = \bigcup_{\alpha, \beta \in \rationals,\ \alpha+\beta \leq t}\{T\leq \alpha\} \cap \{S\leq \beta\}.
	\]
	As $\mcal{F}_t$-measurability is closed under countable union and intersection, the sum is a stopping time. Finally, we have
	\[
	\{\sup_n T_n \leq t\} = \bigcap_{n=1}^\infty \{T_n \leq t\},
	\]
	which is measurable, so the supremum is also a stopping time.
\end{proof}

\noindent\textbf{Problem 2. }
Let $X_t$ be an adapted and continuous stochastic process, and define
\[
T_\Gamma = \inf\{t\geq 0: X_t\in \Gamma\}
\]
for $\Gamma$ a closed set. Show that $T_\Gamma$ is a stopping time.
\begin{proof}
	asdf
\end{proof}

\noindent\textbf{Problem 3. }
Show that if $X_t$ is a martingale with respect to some filtration (say $\mcal{F}_t$) then it is also a martingale with respect to the filtration generated by itself.
\begin{proof}
	Let $\mcal{G}_t = \sigma(X_s: s\leq t)$ be the filtration $X$ generates. We then have $\mcal{G}_t \subseteq \mcal{F}_t$ for all $t$ since $\mcal{G}_t$ is the smallest $\sigma$-algebra with respect to which $X_t$ is measurable. By the law of total expectation and the martingale property of $X_t$ with respect to $\mcal{F}_t$ we have for any $s\leq t$
	\[
	\E[X_t\ |\ \mcal{G}_s] = \E[\E[X_t\ |\ \mcal{F}_s]\ |\ \mcal{G}_s] = \E[X_s\ |\ \mcal{G}_s] = X_s.
	\]
	Thus, $X_t$ is a martingale with respect to $\{\mcal{G}_t\}$.
\end{proof}


\noindent\textbf{Problem 4. }
Let $a,b$ be deterministic and $f,g$ of class I. Show that if
\begin{equation}\label{ints}
a + \int_0^Tf_s\ dB_s = b+ \int_0^Tg_s\ dB_s
\end{equation}
then $a = b$ and $f = g$ a.a. for $(t, \omega) \in (0, T)\times \Omega$.
\begin{proof}
	Since $f$ and $g$ are of class I, $\int_0^t f_s\ dB_s$ and $\int_0^t g_s\ dB_s$ are martingales and $\int_0^0 f_s\ dB_s = 0$ a.s. (the same holds for $g$). Taking the expectation of both sides of the given relation shows that $a = b$ a.s. and
	\[
	\int_0^T(f_s - g_s)\ dB_s = 0.
	\]
	By the It\^o isometry we have
	\[
	0 = \E\left[\left(\int_0^T(f_s - g_s)\ dB)\right)^2\right] = \E\left[\int_0^T(f_s - g_s)^2\ ds\right].
	\]
	We conclude that $f_t(\omega) = g_t(\omega)$ for almost all $(t, \omega)\in (0, T)\times \Omega$.
\end{proof}

\noindent\textbf{Problem 5. }
Assume that $X_t$ is of class I and continuous in mean square on $[0, T]$, that is for $t\in [0, T]$
\[
\E[X_t^2]<\infty,\quad \lim_{s\to t}\E[(X_t-X_s)^2] = 0.
\]
Define
\[
\phi_t^{(n)} = \sum_jX_{t^{(n)}_{j-1}}\chi_{[t^{(n)}_{j-1}, t^{(n)}_j)}(t),\ t^{(n)}_j = j2^{-n}.
\]
Show that for $0\leq t\leq T$
\[
\int_0^tX_s\ dB_s = \lim_{n\to \infty}\int_0^t\phi^{(n)}_s\ dB_s,
\]
where the limit is n $L^2(\Prob)$.
\begin{proof}
	For any $n$ we have by the It\^o isometry
	\[
	\E\left[\left(\int_0^t(X_s - \phi^{(n)}_s)\ dB_s\right)^2\right] = \E\left[\int_0^t(X_s - \phi^{(n)}_s)^2\ ds\right] = \E\left[\sum_j\int_{t_{j-1}^{(n)}}^{t_j^{(n)}} (X_s - X_{t_{j-1}^{(n)}})^2\ ds \right].
	\]
	Now we claim that continuity in mean square on the compact set $[0, T]$ implies uniform continuity in mean square. Assuming this claim, we can choose $n$ large enough so that $\E[(X_s - X_{t_{j-1}^{(n)}})^2]$ is smaller than say $\epsilon$ for all $j$. For $n$ at least this large we have
	\[
	\E\left[\left(\int_0^t(X_s - \phi^{(n)}_s)\ dB_s\right)^2\right] \leq \sum_j(t_j^{(n)} - t_{j-1}^{(n)})\epsilon = \epsilon T.
	\]
	Since the $L^2$ distance between $\int_0^t\varphi_s^{(n)}\ dB_s$ and $\int_0^tX_s\ dB_s$ can be made arbitrarily small, we conclude that $\int_0^t \phi_s^{(n)}\ dB_s\to \int_0^tX_s\ dB_s$ in $L^2$.\\

	\noindent Now we show uniform mean square continuity. Suppose for the sake of contradiction that for some $\epsilon$ there is no $\delta$ such that $|s-t|<\delta$ implies that $\Lp{X_s - X_s}{2}<\epsilon$. Then we can find a sequence $s_n$, $t_n$ so that $|s_n-t_n|<1/n$ but $\Lp{X_s-X_t}{2}>\epsilon$. By the compactness of $[0, T]$, we can assume that $s_n\to s^*\in [0, T]$. We then have $\Lp{X_{s^*}-X_{t_n}}{2}>\epsilon$, but this contradicts the mean square continuity of $X$ at $s^*$.
\end{proof}

\noindent\textbf{Problem 6. }
Let $X_t$ be a deterministic continuous function and 
\[
Y_t = \int_0^tX_s\ dB_s.
\]
Deduce the law of the process $Y$.
\begin{solution}
	
\end{solution}

\end{document}