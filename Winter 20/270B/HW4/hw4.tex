\documentclass[11pt,letterpaper]{report}
\usepackage{amssymb,amsfonts,color,graphicx,amsmath,enumerate}
\usepackage{tikz}
\usepackage{amsthm}
\usepackage{bbm}
\usepackage{hyperref}

\newcommand{\naturals}{\mathbb{N}}
\newcommand{\integers}{\mathbb{Z}}
\newcommand{\complex}{\mathbb{C}}
\newcommand{\reals}{\mathbb{R}}
\newcommand{\mcal}[1]{\mathcal{#1}}
\newcommand{\rationals}{\mathbb{Q}}
\newcommand{\Lp}[2]{\left\|{#1}\right\|_{L^{#2}}}
\newcommand{\field}{\mathbb{F}}
\newcommand{\affine}{\mathbb{A}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Prob}{\mathbb{P}}
\newcommand{\Var}{\text{Var}}
\newcommand{\ind}{\mathbbm{1}}
\newcommand{\Cov}{\text{Cov}}

\newenvironment{solution}
{\begin{proof}[Solution]}
{\end{proof}}

\voffset=-3cm
\hoffset=-2.25cm
\textheight=24cm
\textwidth=17.25cm
\addtolength{\jot}{8pt}
\linespread{1.3}

\begin{document}
\noindent{\em Liam Hardiman\hfill{March 18, 2020} }
\begin{center}
{\bf \Large 270B - Homework 4}
\vspace{0.2cm}
\hrule
\end{center}

\noindent\textbf{Problem 1. }
Let $(X_n)$ be an irreducible recurrent Markov chain with doubly-infinite transition matrix $P$. Let $\psi: \naturals\to \naturals$ be a bounded function satisfying
\[
\sum_{j=1}^\infty P_{ij}\psi(j) = \psi(i)\quad\text{for all }i\in \naturals.
\]
Show that $\psi$ is a constant function.
\begin{proof}
	First we claim that $\psi(X_n)$ is a martingale. Let $\mcal{F}_n$ be the filtration generated by $X_1, \ldots, X_n$. We then have by hypothesis
	\[
	\E[\psi(X_{n+1})|\mcal{F}_n] = \sum_{j}P_{X_n, j}\psi(j) = \psi(X_n),
	\]
	so $\psi(X_n)$ is a martingale with respect to this filtration. We showed on a previous homework assignment that bounded martingales converge almost surely, so $\psi(X_n)\to s$ almost surely for some $s\in \naturals$.\\

	\noindent Suppose $\psi$ is non-constant, so $\psi(i) = u$ and $\psi(j) = v$ for some $i\neq j$, $u\neq v$. Intuitively, since the Markov chain is irreducible and recurrent, it should return to states $i$ and $j$ infinitely often with probability 1. But since $\psi(i)\neq \psi(j)$, this means that $\psi(X_n)$ cannot converge almost surely. 
\end{proof}

\noindent\textbf{Problem 2. }
Let $S$ and $T$ be stopping times with respect to a filtration $(\mcal{F}_n)$. Denote by $(\mcal{F}_T)$ the collection of events $F$ such that $F\cap \{T\leq n\} \in \mcal{F}_n$ for all $n$.
\begin{enumerate}[(a)]
	\item Show that $\mcal{F}_T$ is a $\sigma$-algebra.
	\begin{proof}
		That $\emptyset$ and $\Omega$ are in $\mcal{F}_T$ immediately follows from $T$ being a stopping time. To show closure under complementation, write $F\in \mcal{F}_T$ like so
		\[
		F = (F\cap \{T\leq n\})\cup (F\cap \{T>n\}).
		\]
		This gives
		\[
		F^c\cap \{T\leq n\} = (F\cap \{T\leq n\})^c\cap (F\cap \{T>n\})^c\cap \{T\leq n\}.
		\]
		Since $F\cap \{T\leq n\}$ is in $\mcal{F}_n$, the above set is also in $\mcal{F}_n$.\\

		\noindent As for countable unions, let $F_1, F_2, \ldots \in \mcal{F}_T$. Then
		\[
		\left(\bigcup_{k=1}^\infty F_k\right)\cap \{T\leq n\} = \bigcup_{k=1}^\infty (F_k\cap \{T\leq n\}).
		\]
		Since $F_k\cap \{T\leq n\}\in \mcal{F}_n$ for all $n$, the above set is in $\mcal{F}_n$.
	\end{proof}

	\item Show that $T$ is measurable with respect to $\mcal{F}_T$.
	\begin{proof}
		$T$ is measurable with respect to $\mcal{F}_T$ if and only if $\{T\leq n\}\in \mcal{F}_T$ for all $n$. This follows immediately from the fact that $T$ is a stopping time with respect to the filtration $\mcal{F}_n$. 
	\end{proof}

	\item If $E\in \mcal{F}_S$, show that $E\cap \{S\leq T\}\in \mcal{F}_T$.
	\begin{proof}
		The idea is to write $\{S\leq T\}$ as $\cup_{k=1}^\infty \{T = k\}\cap \{S\leq k\}$. For any $E\in \mcal{F}_S$ we then have
		\begin{align*}
		(E\cap \{S\leq T\})\cap \{T\leq n\} &= \bigcup_{k=1}^\infty( E\cap \{S\leq k\}\cap \{T = k\}\cap\{T\leq n\} )\\
		&= \bigcup_{k=1}^n(E\cap \{S\leq k\}\cap \{T = k\}).
		\end{align*}
		Since $E\in \mcal{F}_S$, $E\cap \{S\leq k\}\in \mcal{F}_k$ for all $k$. Since $T$ is a stopping time with respect to $\mcal{F}_n$, $\{T = k\}\in \mcal{F}_k$ for all $k$. Consequently, the above union is in $\mcal{F}_n$, so $E\cap \{S\leq T\}\in \mcal{F}_T$.
	\end{proof}

	\item Show that if $S\leq T$ a.s. then $\mcal{F}_S\subset \mcal{F}_T$.
	\begin{proof}
		Suppose $F\in \mcal{F}_S$. We then have
		\[
		F\cap \{T\leq n\} = (F\cap \{S\leq n\})\cap \{T\leq n\} \in \mcal{F}_n,
		\]
		so $F\in \mcal{F}_T$.
	\end{proof}
\end{enumerate}

\noindent\textbf{Problem 3. }
Let $(X_n)$ be a uniformly bounded [integrable, right?] martingale with respect to the filtration $(\mcal{F}_n)$. Let $S$ and $T$ be two stopping times satisfying $S\leq T$ a.s. Prove that
\[
X_T = \E[X|\mcal{F}_T]\quad\text{and}\quad X_S = \E[X_T|\mcal{F}_S]
\]
where $X$ is the almost sure limit of $X_n$.
\begin{proof}
	Since $X_n$ is uniformly integrable, we can reconstruct $X_n$ from its a.s. (and $L^1$) limit:
	\[
	X_n = \E[X|\mcal{F}_n].
	\]
	Now for any $F\in \mcal{F}_T$ we have $F\cap \{T=n\} \in \mcal{F}_n$ for all $n$.
	\[
	\int_FX_T\ d\Prob = \sum_{n=0}^\infty\int_{F\cap \{T=n\}}X_T\ d\Prob = \sum_{n=0}^\infty \int_{F\cap \{T = n\}}X_n\ d\Prob.
	\]
	By the definition of conditional expectation, the last integral above is equal to
	\[
	\sum_{n=1}^\infty\int_{F\cap \{T = n\}}X\ d\Prob = \int_FX\ d\Prob.
	\]
	Again, by the definition of conditional expectation, we have $X_T = \E[X|\mcal{F}_T]$.\\

	\noindent By problem 2(d), we have that since $S\leq T$ a.s., $\mcal{F}_S\subset \mcal{F}_T$. Consequently, we have by the law of total expectation
	\[
	\E[X_T|\mcal{F}_S] = \E[\E[X|\mcal{F}_T]\ |\ \mcal{F}_S] = \E[X|\mcal{F}_S] = X_S.
	\]
\end{proof}

\noindent\textbf{Problem 4. }
A die is rolled repeatedly. Which of the following are Markov chains? For those that are, compute the transition matrix.
\begin{enumerate}[(a)]
	\item The largest number $X_n$ shown up to the $n$-th roll.
	\begin{solution}
		Intuitively, this should be a Markov chain: to check if the current roll is the largest thus far, we need only compare it to the largest roll seen before. More concretely, consider $1\leq i_1, i_2,  \ldots, i_n\leq 6$. Then
		\[
		\Prob[X_{n+1} = i_{n+1}\ |\ X_n = i_n, \ldots, X_1 = i_1] = \begin{cases}
			i_n/6&\text{if }i_{n+1} = i_n\\
			1/6&\text{if }i_{n+1} > i_n\\
			0&\text{otherwise}
		\end{cases} = \Prob[X_{n+1} = i_{n+1}\ |\ X_n = i_n].
		\]
		The state space of this Markov chain is $\{1, 2, 3, 4, 5, 6\}$ and the transition matrix $P_{i,j}$ is given by
		\[
		P_{i,j}= \begin{cases}
			i/6&\text{if }j = i\\
			1/6&\text{if }j > i\\
			0&\text{otherwise}
		\end{cases}
		\]
	\end{solution}

	\item The number $N_n$ of sixes in $n$ rolls.
	\begin{solution}
		$N_n$ is a Markov chain: the number of sixes on the $n+1$-st roll will either be the same as or one greater than the number of sixes on the $n$-th roll. $N_{n+1}$ will only depend on $N_n$ since the dice rolls are independent. The state space is the set of nonnegative integers and the transition matrix is given by
		\[
		P_{i,j} = \begin{cases}
			5/6&\text{if }j = i\\
			1/6&\text{if }j = i+1\\
			0&\text{otherwise}
		\end{cases}.
		\]
	\end{solution}

	\item At time $r$, the time $C_r$ since the most recent six.
	\begin{solution}
		If $E_n$ is the even that the $n$-th roll is a six, then we have $C_{n+1} = C_n + \ind_{E_{n+1}}$. Since the $(n+1)$-st roll is independent of the previous states of the process, we see that $C_n$ is a Markov chain. The state space is the set of nonnegative integers and its transition matrix is given by
		\[
		P_{i,j} = \begin{cases}
			1/6&\text{if }j = i+1\\
			5/6&\text{if }j = i\\
			0&\text{otherwise}
		\end{cases}.
		\]
	\end{solution}

	\item At time $r$, the time $B_r$ until the next six.
	\begin{solution}
		If $B_r > 1$, then $B_{r+1} = B_r - 1$ almost surely - if the next six will come in $B_r>1$ rolls, then on the next roll it will come in $B_r-1$ rolls. Now if $B_r  = 1$, then the process ``restarts'' and the time until the next six will follow a geometric distribution with parameter $1/6$, i.e. $\Prob[B_{r+1} = j] = \frac{1}{6}(\frac{5}{6})^{j-1}$. In either case, the distribution of $B_{r+1}$ depends only on the value of $B_r$ and we have a Markov chain. The transition matrix is given by
		\[
		P_{i,j} = \begin{cases}
			1&\text{if }i>1,\ j = i-1\\
			\frac{1}{6}(\frac{5}{6})^{j-1}&\text{if }i=1,\ j\geq 1\\
			0&\text{otherwise}
		\end{cases}.
		\]
	\end{solution}
\end{enumerate}

\noindent\textbf{Problem 5. }
Let $S_n$ be a simple random walk starting at $S_0 = 0$. Show that $X_n = |S_n|$ is a Markov chain.
\begin{proof}
	If $|S_n| = i_n$, then $S_n = i_n$ or $S_n = -i_n$. We then have for $i_n > 0$
	\begin{align*}
	\Prob[|S_{n+1}| = i_{n+1}\ |\ |S_n| = i_n, \ldots, |S_1|=i_1]&= \Prob[S_{n+1} = i_{n+1}\ |\ S_n = i_n, \ldots, |S_1|=i_1]\\
	&+\Prob[S_{n+1}=-i_{n+1}\ |\ S_n = -i_n, \ldots, |S_1|=i_1]
	\end{align*}
\end{proof}

\noindent\textbf{Problem 6. }
Let $(X_n)$ be a Markov chain, and let $T$ be a stopping time with respect to the filtration $\mcal{F}_n = \sigma(X_1, \ldots, X_n)$. Show that
\[
\Prob[X_{T+1}=j\ |\ X_k = x_k\text{ for }0\leq k<T,\ X_T = i] = \Prob[X_{T+1}=j\ |\ X_T=i]
\]
for all $m\geq 0$ $i,j$ and $x_k$.
\begin{proof}
	For ease of notation, let $E_m = \{X_k = x_k$ for $0\leq k\leq m\}$. We then have
	\begin{equation}\label{sum}
	\Prob[X_{T+1} = j\ |\ E_T]= \sum_{n=1}^\infty\Prob[X_{T+1}=j\ |\ E_T,\ T=n]\cdot\Prob[T=n\ |\ E_T].
	\end{equation}
	By the definition of conditional probability we have
	\[
	\Prob[X_{T+1}=j\ |\ E_T,\ T=n] = \frac{\Prob[X_{T+1}=j,\ E_T,\ T=n]}{\Prob[E_T,\ T=n]} = \frac{\Prob[X_{n+1}=j,\ E_n,\ T=n]}{\Prob[E_n,\ T=n]}.
	\]
	Now since $T$ is a stopping time, it is $\mcal{F}_n$ measurable. I want to say that $E_n\cap \{T=n\} = E_n$. This gives, by the Markov property
	\[
	\Prob[X_{T+1}=j\ |\ E_T,\ T=n] = \frac{\Prob[X_{n+1}=j, E_n]}{\Prob[E_n]} = \Prob[X_{n+1}=j\ |\ E_n] = \Prob[X_{n+1}=j\ |\ X_n = i_n].
	\]
	Combining this with (\ref{sum}), and using the presumed stationarity of the chain, we have
	\[
	\Prob[X_{T+1} =j\ |\ E_T] = \Prob[X_{n+1}=j\ |\ X_n = i_n] = \Prob[X_{T+1}=j\ |\ X_T=i_T].
	\]
\end{proof}

\noindent\textbf{Problem 7. }
Find an example of two Markov chains $(X_n)$ and $(Y_n)$ such that $X_n+Y_n$ is not a Markov chain.
\begin{solution}
	Let $X_n$ be a simple symmetric random walk on $\integers$ that starts at the origin and let $Y_n$ be given by
	\[
	Y_n = \begin{cases}
		1&\text{if }X_1 = 1\\
		0&\text{if }X_1 = -1
	\end{cases}.
	\]
	We've established that $X_n$ is a Markov chain. Since $Y_n$ is constant, it is also a Markov chain. However, we claim that $Z_n = X_n+Y_n$ is not a Markov chain. Intuitively, the steps $Z_n$ can take to get to $Z_{n+1}$ depend on the first step, $Z_0$. Concretely, consider $\Prob[Z_5 = 3\ |\ Z_4 = 2]$. $Z_4$ could've reached 2 in several different ways, e.g.: $-1, +1, +1, +1$ or $+2,0, 0, 0$. If $Z_1 = -1$, then the probability that $Z_5=3$ is $1/2$. On the other hand, if $Z_1 = 2$, then the probability that $Z_5 = 3$ is $0$.
\end{solution}

\noindent\textbf{Problem 8. }
A particle performs a random walk on the vertices of a three-dimensional cube. At each step it remains where it is with probability 1/4 or moves to one of its neighboring vertices each having probability 1/4. Compute the mean number of steps until the particle returns to the vertex from which the walk started.
\begin{solution}
	Suppose that the particle starts at vertex $u$. Let $\mu_u$ be the expected return time. At each step the particle can stay put with positive probability, so the Markov chain is aperiodic. Furthermore, the cube is connected and finite, so the Markov chain is also irreducible. This chain then admits a stationary distribution $\pi$. We also know that $\mu_u = \frac{1}{\pi_u}$. The uniform measure $\pi_u = \frac{1}{8}$ satisfies the detailed balance equations: for $u$ and $v$ adjacent (note that $u$ is adjacent to itself here)
	\[
		\pi_uP_{u,v} = \pi_vP_{v,u} \iff \frac{1}{8}\cdot \frac{1}{4} = \frac{1}{8}\cdot \frac{1}{4}.
	\]
	We conclude that the mean number of steps until the particle returns to its starting location is 8.
\end{solution}

\noindent\textbf{Problem 9. }
Prove that the symmetric random walk on $\integers^2$ is recurrent while the symmetric random walk on $\integers^3$ is transient.
\begin{proof}
	Let $S_n$ be the position of the random walk at time $n$. We showed in class that a state $x$ is recurrent if
	\[
	\sum_{n=1}^\infty \Prob[S_n = x] = \infty.
	\]
	Since recurrence is a class property and all lattice points in $\integers^2$ communicate with one another, it suffices to show that $\sum_{n=1}^\infty \Prob[S_n =0]= \infty$.\\

	\noindent A particle moving according to this random walk can only return to the origin on even time steps. Suppose $S_{2n} = 0$. Then the particle's up and down steps must be equal, as must be its left and right steps. If the particle takes $m$ steps up, $0\leq m\leq n$, then it must take $m$ steps down. The remaining $2n-2m$ steps must be in the left-right directions, so we have $n-m$ left steps and $n-m$ right steps. The number of ways to choose these steps is given by the multinomial coefficient, $\binom{2n}{m,m, n-m, n-m}$. There are $4^{2n}$ possible step sequences of length $2n$, so we have
	\begin{align*}
		\Prob[S_{2n} = 0] = 4^{-2n}\sum_{m=0}^n\binom{2n}{m, m, n-m, n-m}.
	\end{align*}
	The multinomial coefficient $\binom{2n}{m, m, n-m, n-m}$ represents choosing two sets of $m$ elements and two sets of $n-m$ elements. This process can be thought of as making two sets with $n$ elements, each with $m$ distinguished elements. This can be done by first splitting the $2n$ elements into two sets of size $n$, and then picking $m$ elements from both of these subsets. This gives
	\[
	\Prob[S_{2n}=0] = 4^{-2n}\sum_{m=0}^n\binom{2n}{n}\binom{n}{m}^2.
	\]
	We claim that $\sum_{m=0}^n\binom{n}{m}^2 = \binom{2n}{n}$. Split the $2n$ elements into two sets of size $n$. Each term in this sum represents picking $m$ elements from one set and $n-m$ from the other, since $\binom{n}{m} = \binom{n}{n-m}$. Summing over $m$ then counts all ways to choose a subset of size $n$. We then have
	\[
	\Prob[S_{2n}=0] = \frac{1}{4^{2n}}\binom{2n}{n}^2.
	\]
	We apply Stirling's approximation to check out the asymptotics:
	\[
	\Prob[S_{2n}=0] \sim \frac{1}{4^{2n}}\left(\frac{2^{2n}}{\sqrt{\pi n}}\right)^2 =\frac{1}{\pi n}.
	\]
	This quantity isn't summable in $n$, so the Markov chain is recurrent.
\end{proof}

\noindent\textbf{Problem 10. }
Which of the following are reversible Markov chains?
\begin{enumerate}[(a)]
	\item Move from 0 to 1 with probability $p$ and stay at 0 with probability $1-p$; move from 1 to 0 with probability $q$ and stay at 1 with probability $1-q$.
	\begin{solution}
		If this chain were reversible, it would give an invariant measure $\pi$ that satisfies the detailed balance equations. The transition matrix for this chain is given by
		\[
		P = \begin{bmatrix}
			1-p & p\\
			q & 1-q
		\end{bmatrix}.
		\]
		The condition that $[\pi_0\ \pi_1]$ is a left eigenvector with eigenvalue 1 forces $p\pi_0 = q\pi_1$. This is exactly the detailed balance condition, so the chain is reversible if and only if it has a stationary measure. If $p = q= 0$, then $P$ is the identity matrix and every measure is stationary: the chain is constant. If neither $p$ nor $q$ is zero, then $\pi_0 = \frac{q}{p}\pi_1$ and normalization gives the unique stationary measure. If say $p = 0$ and $q\neq 0$, then $[1\ 0]$ is the stationary measure. In all cases, the chain is reversible.
	\end{solution}

	\item A random walk on the vertices of a given triangle: at each time, move to the next vertex counterclockwise with probability $p$ and clockwise with probability $1-p$.
	\begin{solution}
		Since the triangle is an odd cycle, this chain is aperiodic. All states communicate, so the chain is also irreducible. We conclude that the chain admits a unique stationary measure. The chain is reversible if and only if this measure satisfies the detailed balance condition. If we label the vertices of the triangle 1, 2, and 3 in a clockwise fashion, the transition matrix of the chain becomes
		\[
		P = \begin{bmatrix}
			0 & 1-p & p\\
			p & 0 & 1-p\\
			1-p & p & 0
		\end{bmatrix}.
		\]
		We can see by inspection that the uniform measure $\pi = \frac{1}{3}[1\ 1\ 1]$ is stationary. $\pi$ satisfying the detailed balance condition $\pi_i P_{i,j} = \pi_jP_{j,i}$ is equivalent to $P$ being symmetric. This holds if and only if $p = 1/2$. We conclude that the chain is reversible if and only if $p=1/2$.
	\end{solution}
\end{enumerate}

\noindent\textbf{Problem 11. }
A king performs a random walk on a chessboard; at each step it is equally likely to make any one of the available moves and never stays put. What is the mean recurrence time of a corner square?
\begin{solution}
	The chain is clearly irreducible since the king can move between any two squares in a finite amount of time. It is also aperiodic since if the king starts on any square, it can return in two or three moves. Thus, the chain admits a unique stationary measure.\\

	\noindent We showed in class that in a random walk on a connected graph, the entry $\pi_i$ of the stationary distribution is proportional to the degree of vertex $i$,
	\[
	\pi_i = \frac{\deg i}{2\cdot e},
	\]
	where $e$ is the number of edges in the graph. We use the handshaking lemma to count the number of edges:
	\[
	2e = \sum_{i}\deg i = \underbrace{3\cdot 4}_{\text{corners}} + \underbrace{5\cdot 24}_{\text{non-corner boundary}} + \underbrace{8\cdot 36}_{\text{internal}} = 420.
	\]
	The stationary probability of a corner vertex is then $3/420 = 1/140$. Since the mean return time is the reciprocal of the stationary probability, the mean return time of a corner vertex is 140.
\end{solution}

\end{document}