\documentclass[11pt,letterpaper]{report}
\usepackage{amssymb,amsfonts,color,graphicx,amsmath,enumerate}
\usepackage{tikz}
\usepackage{amsthm}
\usepackage{bbm}
\usepackage{hyperref}

\newcommand{\naturals}{\mathbb{N}}
\newcommand{\integers}{\mathbb{Z}}
\newcommand{\complex}{\mathbb{C}}
\newcommand{\reals}{\mathbb{R}}
\newcommand{\mcal}[1]{\mathcal{#1}}
\newcommand{\rationals}{\mathbb{Q}}
\newcommand{\Lp}[2]{\left\|{#1}\right\|_{L^{#2}}}
\newcommand{\field}{\mathbb{F}}
\newcommand{\affine}{\mathbb{A}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Prob}{\mathbb{P}}
\newcommand{\Var}{\text{Var}}
\newcommand{\ind}{\mathbbm{1}}
\newcommand{\Cov}{\text{Cov}}

\newenvironment{solution}
{\begin{proof}[Solution]}
{\end{proof}}

\voffset=-3cm
\hoffset=-2.25cm
\textheight=24cm
\textwidth=17.25cm
\addtolength{\jot}{8pt}
\linespread{1.3}

\begin{document}
\noindent{\em Liam Hardiman\hfill{February 24, 2020} }
\begin{center}
{\bf \Large 270B - Homework 3}
\vspace{0.2cm}
\hrule
\end{center}

\noindent\textbf{Problem 1. }
Let $X_1, X_2, \ldots$ be independent random variables with means $\mu_i$ and finite variances $\sigma_i^2$. Consider the sums $S_n = X_1 + \cdots + X_n$. Find sequences of real numbers $(b_i)$ and $(c_i)$ such that $S_n^2 + b_nS_n + c_n$ is a martingale with respect to the $\sigma$-algebras generated by $X_1, \ldots, X_n$.
\begin{solution}
	Let's start by centering the sum: define the random variable $M_n = S_n - \sum_{i=1}^n \mu_i$. Since the $X_i$'s are independent, we have $\Var[M_n] = \sum_{i=1}^n \sigma_i^2$. We claim that
	\[
	V_n = M_n^2 - \sum_{i=1}^n\sigma_i^2 = \left(S_n - \sum_{i=1}^n\mu_i\right)^2 - \sum_{i=1}^n\sigma_i^2
	\]
	is a martingale with respect to the filtration $\mcal{F}_n = \sigma(X_1, \ldots, X_n)$. Let's start the computation.
	\begin{align*}
		\E[V_{n+1}|\mcal{F}_n] &= \E[S_{n+1}^2] - 2\left(\sum_{i=1}^{n+1}\mu_i\right)\E[S_{n+1}|\mcal{F}_n] + \left(\sum_{i=1}^{n+1}\mu_i\right)^2 - \sum_{i=1}^{n+1}\sigma_i^2\\
		&= S_n^2 + 2S_n\mu_{n+1} + \E[X_{n+1}^2] - 2\left(\sum_{i=1}^{n+1}\mu_i\right)(S_n + \mu_{n+1}) + \left(\sum_{i=1}^{n+1}\mu_i\right)^2 - \sum_{i=1}^{n+1}\sigma_i^2\\
		&= S_n^2 -2\left(\sum_{i=1}^n\mu_i\right)S_n + \E[X_{n+1}^2] - 2\mu_{n+1}^2 + \left(\sum_{i=1}^n\mu_i\right)^2 + \mu_{n+1}^2 - \sum_{i=1}^{n+1}\sigma_i^2\\
		&= S_n^2 - 2\left(\sum_{i=1}^n\mu_i\right)S_n + \left(\sum_{i=1}^n\mu_i\right)^2 - \sum_{i=1}^n\sigma_i^2\\
		&= V_n.
	\end{align*}
	Here we've used the fact that $S_n$ is $\mcal{F}_n$-measurable and $X_{n+1}$ is independent of $\mcal{F}_n$. The sequences we want are then
	\[
	b_n = -2\sum_{i=1}^n\mu_i,\qquad c_n = \left(\sum_{i=1}^n\mu_i\right)^2 - \sum_{i=1}^n\sigma_i^2.
	\]
\end{solution}

\noindent\textbf{Problem 2. }
\begin{enumerate}[(a)]
	\item Show that if $(X_n)$ and $(Y_n)$ are martingales with respect to the same filtration, then $X_n\lor Y_n$ is a submartingale.
	\begin{proof}
		We use the trusty identity
		\[
		X_n\lor Y_n = \frac{1}{2}[(X_n+Y_n) + |X_n - Y_n|].
		\]
		Since the sum of martingales is a martingale and conditional Jensen says the absolute value of a martingale is a submartingale, we have
		\begin{align*}
			\E[X_{n+1}\lor Y_{n+1}|\mcal{F}_n] &= \frac{1}{2}(\E[X_{n+1}+Y_{n+1}|\mcal{F}_n] + \E[|X_{n+1} -Y_{n+1}|\ |\ \mcal{F}_n])\\
			&\geq \frac{1}{2}[(X_n + Y_n) + |X_n - Y_n|]\\
			&= X_n\lor Y_n.
		\end{align*}
		Hence, $X_n\lor Y_n$ is a submartingale.
	\end{proof}

	\item Give an example showing that $X_n \lor Y_n$ need not be a martingale.
	\begin{proof}
		
	\end{proof}
\end{enumerate}

\noindent\textbf{Problem 3. }
Give an example of a martingale $(X_n)$ such that $X_n\to -\infty$ a.s.
\begin{solution}
	Durrett gives a hint to let $X_n = \xi_1 + \cdots + \xi_n$ for some independent centered $\xi_i$'s. The idea is to concentrate most of the mass of $\xi_i$ around some negative value and put the rest (some summable amount) around some positive value, then apply Borel-Cantelli.\\

	\noindent Concretely, let $\xi_i$ be given by
	\[
	\xi_i = \begin{cases}
		2^j&\text{with probability }\frac{1}{2^j}\\
		-\frac{1}{1-2^{-j}}&\text{with probability }1-\frac{1}{2^j}
	\end{cases}.
	\]
	Clearly $\xi_i$ is centered, so $X_n = \xi_1 + \cdots + \xi_n$ is a martingale. Note that
	\[
	\sum_{i=1}^\infty \Prob[\xi_i = 2^j] = \sum_{i=1}^\infty \frac{1}{2^j} = 1<\infty.
	\]
	By Borel-Cantelli, we have that $\xi_i = -\frac{1}{1-2^{-j}}$ eventually with probability 1, so $X_n\to -\infty$ a.s.
\end{solution}

\noindent\textbf{Problem 4. }
Let $(X_n)$ be a martingale that is bounded a.s. either above or below by some constant $M$. Show that $\sup_n \E|X_n|<\infty$.
\begin{proof}
	The main idea is that a nonnegative martingale $(X_n)$ converges a.s. to some $X$ and $\E[X]\leq \E[X_1]$. This is a theorem in Durrett. We establish it by noting that our proof of the Martingale convergence theorem actually shows that we need only assume that $\sup_n\E[X_n^+]<\infty$ in order to guarantee a.s. convergence. Once we have this, note that $-X_n \leq 0$ is a martingale with $\E[(-X_n)^+] = 0$, so by martingale convergence, $X_n$ converges a.s. to some $X$ and $\E[X_1] \geq \E[X]$ by Fatou.\\
	\noindent Now if $X_n$ is bounded below, then $X_n+M$ is a nonnegative martingale. By the martingale convergence theorem, $X_n+M$ converges almost surely to some limit $Y$ with $\E|Y|<\infty$. Consequently, $X_n$ also converges a.s. to an integrable function, so $\sup_n \E|X_n|<\infty$. If $X_n$ is bounded above, then $-X_n+M$ is a nonnegative martingale and the same argument works.
\end{proof}

\noindent\textbf{Problem 5. }
Let $Z_1, Z_2, \ldots$ be nonnegative iid random variables with $\E[Z_i] = 1$ and $\Prob[Z_i = 1]<1$. Show that as $n\to \infty$,
\[
\prod_{i=1}^n Z_i\to 0\quad\text{a.s.}
\]
\begin{proof}
	First note that $M_n = \prod_{i=1}^nZ_i$ is indeed a martingale:
	\[
	\E[M_{n+1}|\mcal{F}_n] = \E[Z_{n+1}M_n|\mcal{F}_n] = M_{n+1},
	\]
	where $\mcal{F}_n = \sigma(Z_1, \ldots, Z_n)$. Since $M_n$ is a nonnegative martingale, it converges to some $X$ a.s. with $\E[X] \leq \E[Z_1] = 1$. For any $\epsilon>0$ we have
	\[
	\Prob[|M_{n+1}-M_n| > \epsilon] = \Prob[M_n|Z_{n+1}-1|>\epsilon].
	\]
	Now if $M_n>\sqrt{\epsilon}$ and $|Z_{n+1}-1|>\sqrt{\epsilon}$, then clearly $M_n|Z_{n+1}-1|>\epsilon$. We then have by independence
	\[
	\Prob[|M_{n+1}-M_n|>\epsilon] \geq \Prob[M_n>\sqrt{\epsilon}]\cdot\Prob[|Z_{n+1}-1|>\sqrt{\epsilon}].
	\]
	Now since $\Prob[Z_{n+1} = 1]<1$, we have that for $\epsilon$ sufficiently small, $\Prob[|Z_{n+1}-1|>\epsilon] \geq \delta>0$ for some $\delta$. Since $M_n$ converges almost surely, it converges in measure as well, so the left-hand side of the above inequality goes to zero. Since the $\Prob[|Z_{n+1}-1|>\sqrt{\epsilon}]$ term is bounded below by a positive constant, we must have that $\Prob[M_n>\sqrt{\epsilon}]\to 0$, so $M_n\to 0$ in probability. Since $M_n$ converges almost surely and the a.s. limit is the same as the probability limit, $M_n\to 0$ a.s.
\end{proof}

\noindent\textbf{Problem 6. }
Let $(X_n)$ be a martingale and let $\Delta_n = X_n - X_{n-1}$ be the martingale differences. Prove that if $X_0=0$ and $\sum_{n=1}^\infty \Delta_n^2<\infty$ then $X_n$ converges in $L^2$ to some random variable $X$. (I tried doing the problem as stated and it didn't seem to work. I talked with Xiaowen and she said that we need to assume $\sum \E[\Delta_n^2]<\infty$. This is also how it's stated in Durrett.)
\begin{proof}
 	For any $m, n$ we have $X_n-X_m = \sum_{i=m+1}^n \Delta_i$. From this we deduce
 	\[
 	\E[|X_n - X_m|^2] = \E\left[\left(\sum_{i=m+1}^n\Delta_i\right)^2\right] = \sum_{i=m+1}^n\E[\Delta_i^2] + 2\sum_{m+1\leq i<j}^n\E[\Delta_i\Delta_j].
 	\]
 	Since martingale increments are uncorrelated, $\E[\Delta_i\Delta_j] = \E[\Delta_i]\E[\Delta_j] = 0$. Since $\sum \E[\Delta_i^2]<\infty$, the tail sum goes to zero, so for $m,n$ large enough, the above sum can be made arbitrarily small. $(X_n)$ is then Cauchy in $L^2$, so it converges in $L^2$ by completeness.
\end{proof} 

\noindent\textbf{Problem 7. }
Construct a branching process $(Z_n)$ as follows. Let $X$ be a random variable with mean $\mu$ and variance $\sigma^2$; it specifies the distribution of the offspring. Set
\[
Z_{n+1} = X_1^{(n+1)} + \cdots + X_{Z_n}^{(n+1)},
\]
to be the size of the population at time $n+1$, where all $X_i^{(k)}$ are iid random variables distributed identically with $X$.
\begin{enumerate}[(a)]
	\item Show that $Y_n = Z_n/\mu^n$ defines a martingale (with respect to the filtration $\mcal{F}_n$ generated by $X_j^{(k)}$, $1\leq j\leq Z_n$, $k\leq n$.)
	\begin{proof}
		We compute, critically using the fact that $Z_n$ is $\mcal{F}_n$-measurable.
		\begin{align*}
			\E[Y_{n+1}|\mcal{F}_n] &= \frac{1}{\mu^{n+1}}\E[Z_{n+1}|\mcal{F}_n]\\
			&= \frac{1}{\mu^{n+1}}\E[X_1^{(n+1)} + \cdots + X_{Z_n}^{(n+1)}|\mcal{F}_n]\\
			&= \frac{1}{\mu^{n+1}}\cdot \mu Z_n\\
			&= Y_n.
		\end{align*}
	\end{proof}

	\item Show that
	\[
	\E[Z_{n+1}^2|\mcal{F}_n] = \mu^2Z_n^2 + \sigma^2Z_n.
	\]
	\begin{proof}
		We compute.
		\begin{align*}
			\E[Z_{n+1}^2|\mcal{F}_n] &= \sum_{i=1}^{Z_n}\E[(X^{(n+1)}_i)^2] + 2\sum_{1\leq i<j\leq Z_n}\E[X_i^{(n+1)}X_j^{(n+1)}]\\
			&= Z_n(\sigma^2+\mu^2) + Z_n(Z_n-1)\mu^2\\
			&= \mu^2Z_n^2 + \sigma^2Z_n.
		\end{align*}
	\end{proof}

	\item Deduce that $(Y_n)$ is bounded in $L^2$ if and only if $\mu>1$.
	\begin{proof}
		We have
		\[
		\E[Y_n^2] = \frac{1}{\mu^{2n}}\E[\E[Z_n^2|\mcal{F}_{n-1}]] = \frac{1}{\mu^{2n}}(\mu^2\E[Z_{n-1}^2] + \sigma^2\mu^{n-1}) = \E[Y_{n-1}^2] + \frac{\sigma^2}{\mu^{n+1}}.
		\]
		Summing over $n$ and using $Y_0 = 1$ gives
		\[
		\E[Y_n^2] = \begin{cases}
			1+n\sigma^2&\text{if }\mu=1\\
			1+\frac{\sigma^2}{\mu^2-\mu}(1-\frac{1}{\mu^n})&\text{otherwise}
		\end{cases}.
		\]
		If $n\leq 1$, this quantity tends toward $\infty$ and it tends toward $\frac{\sigma^2}{\mu^2-\mu}$ otherwise.
	\end{proof}

	\item Show that when $\mu>1$, the $L^2$ limit $Y$ of $Y_n$ satisfies
	\[
	\Var[Y] = \frac{\sigma^2}{\mu(\mu-1)}.
	\]
	\begin{proof}
		Assuming we have convergence in $L^2$, we have
		\[
		\Var[Y] = \E[Y^2] - \E[Y]^2 = \lim_{n\to \infty}\E[Y_n^2] - 1 = \lim_{n\to \infty}\frac{\sigma^2}{\mu(\mu-1)}\left(1-\frac{1}{\mu^n}\right) = \frac{\sigma^2}{\mu(\mu-1)}.
		\]
	\end{proof}
\end{enumerate}

\noindent\textbf{Problem 8. }
Find an example of a martingale $(X_n)$ that converges a.s. to some random variable $X$, but for which $\limsup_n \E|X_n| = \infty$.
\begin{solution}
	Define the sequence $(a_n)$ by
	\[
	a_1 = 2,\quad a_n = 4\sum_{i=1}^n a_i.
	\]
	Also define the independent random variables $Z_n$ by
	\[
	Z_n = \begin{cases}
		a_n&\text{with probability }1/(2n^2)\\
		0&\text{with probability }1-n^{-2}\\
		-a_n&\text{with probability }1/(2n^2)
	\end{cases}.
	\]
	Finally, define $X_n$ by $X_n = \sum_{i=1}^n Z_i$. Since each $Z_i$ is centered, $X_n$ is clearly a martingale with respect to the filtration $\mcal{F}_n=\sigma(Z_1, \ldots, Z_n)$.\\

	\noindent Now $\Prob[Z_n]\neq 0 = \frac{1}{n^2}$. Since this quantity is summable, we have by Borel-Cantelli that $\Prob[Z_n \neq 0\text{ i.o.}] = 0$. Consequently, $X_n$ converges almost surely.\\

	\noindent If $Z_n \neq 0$, the minimum possible value for $X_n$ is
	\[
	a_n - \sum_{i=1}^{n-1}a_i = \frac{3}{4}a_n,
	\]
	which corresponds to taking a step of size $a_n$ in one direction and every previous step having size $a_i$ in the opposite direction. By induction we have $a_n = 8\cdot 5^{n-2}$ for $n\geq 3$.  The probability of taking this step is at least $1/(2n^2)$, so by Markov's inequality we have
	\[
	\E|X_n| \geq \frac{3}{4}a_n\Prob\left[|X_n| \geq \frac{3}{4}a_n\right] \geq \frac{3}{4} \cdot (8\cdot 5^{n-2})\cdot \frac{1}{2n^2}\to \infty.
	\]
\end{solution}

\end{document}