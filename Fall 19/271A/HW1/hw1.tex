\documentclass[11pt,letterpaper]{report}
\usepackage{amssymb,amsfonts,color,graphicx,amsmath,enumerate}
\usepackage{tikz}
\usepackage{amsthm}

\newcommand{\naturals}{\mathbb{N}}
\newcommand{\integers}{\mathbb{Z}}
\newcommand{\complex}{\mathbb{C}}
\newcommand{\reals}{\mathbb{R}}
\newcommand{\exreals}{\overline{\mathbb{R}}}
\newcommand{\mcal}[1]{\mathcal{#1}}
\newcommand{\mable}{measurable}
\newcommand{\quats}{\mathbb{H}}
\newcommand{\rationals}{\mathbb{Q}}
\newcommand{\norm}{\trianglelefteq}
\newcommand{\Aut}{\text{Aut}}
\newcommand{\disk}{\mathbb{D}}
\newcommand{\halfplane}{\mathbb{H}}
\newcommand{\Lp}[2]{\left\|{#1}\right\|_{L^{#2}}}
\newcommand{\supp}[1]{\text{supp}({#1})}
\newcommand{\Hom}[2]{\text{Hom}_{{#1}}({#2})}
\newcommand{\tr}{\text{tr}}
\newcommand{\field}[1]{\mathbb{F}_{{#1}}}
\newcommand{\Gal}[1]{\text{Gal}\left({#1}\right)}
\newcommand{\esssup}{\text{ess sup }}
\newcommand{\essinf}{\text{ess inf }}
\newcommand{\affine}{\mathbb{A}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\prob}{\mathbb{P}}

\newenvironment{solution}
{\begin{proof}[Solution]}
{\end{proof}}

\voffset=-3cm
\hoffset=-2.25cm
\textheight=24cm
\textwidth=17.25cm
\addtolength{\jot}{8pt}
\linespread{1.3}

\begin{document}
\noindent{\em Liam Hardiman\hfill{October 14, 2019} }
\begin{center}
{\bf \Large 271A - Homework 1}
\vspace{0.2cm}
\hrule
\end{center}

\begin{enumerate}
	\item \begin{enumerate}
		\item Let $\Delta_1$, $\Delta_2, \ldots$ be independent random variables with mean 0 and variance 1. Let $X_1 = \Delta_1$ and for $n = 1, 2, \ldots$ let $X_{n+1} = X_n + \Delta_{n+1}f_n(X_1, \ldots, X_n)$ for $f_n$ given bounded deterministic functions. Show that $\{X_n\}$ is a martingale (specify the filtration).
		\begin{solution}
			Let $\{\mcal{F}_n\}$ be the filtration given by $\mcal{F}_n = \sigma(X_1, \ldots, X_n)$. We have that $\E[|X_1|] = \E[|\Delta_1|]<\infty$, since $\Delta_1$ has finite mean. Suppose now that $\E[|X_n|]<\infty$ for all $n \leq k$ for some $k$. We then have
			\begin{align*}
				\E[|X_{k+1}|] &= \E[|X_k + \Delta_{k+1}f_k(X_1, \ldots, X_k)|]\\
				&\leq \E[|X_k|] + \Lp{f_k}{\infty}\cdot\E[|\Delta_{k+1}|]\\
				&<\infty.
			\end{align*}
			By induction, each $X_n$ is integrable. Since we're dealing with a discrete stochastic process, it suffices to check the martingale property on consecutive variable-filtration pairs, $\E[X_{n+1}|\mcal{F}_n]$. Here's a computation.
			\begin{align*}
				\E[X_{n+1}| \mcal{F}_n] &= \E[X_{n+1} - X_n + X_n | \mcal{F}_n]\\
				&= \E[\Delta_{n+1}f_n(X_1, \ldots, X_n)|\mcal{F}_n] + X_n\\
				&= \E[\Delta_{n+1}|\mcal{F}_n]\cdot f_n(X_1, \ldots, X_n) + X_n \quad(f_n(X_1, \ldots, X_n)\text{is }\mcal{F}_n\text{ measurable})\\
				&= \E[\Delta_{n+1}]\cdot f_n(X_1, \ldots, X_n) +X_n\quad (\Delta_{n+1}\text{ is independent of }\mcal{F}_n)\\
				&= X_n.
			\end{align*}
			Thus, $\{X_n\}$ is a martingale adapted to the filtration $\{\mcal{F}_n\}$.
		\end{solution}

		\item Let $Y_1, \ldots$ be independent random variables with mean 0 and variance $\sigma^2$. Let $X_n = (\sum_{k=1}^nY_k)^2 - n\sigma^2$ and show that $\{X_n\}$ is a martingale.
		\begin{solution}
			Let $\mcal{F}_n = \sigma(X_1, \ldots, X_n)$. Let's verify that the variables $X_n$ are integrable.
			\begin{align*}
				\E[|X_n|] & \leq \sum_{k=1}^n \E[Y_k^2] + 2\sum_{1\leq i<j\leq n}\E[Y_iY_j] + n\sigma^2\\
				&= 2n\sigma^2\quad (\text{since }Y_i \text{ and }Y_j\text{ are independent for }i \neq j).
			\end{align*}
			Great. Now let's show that $\E[X_{n+1}|\mcal{F}_n] = X_n$.
			\begin{align*}
				\E[X_{n+1}|\mcal{F}_n] &= \E[X_{n+1} - X_n + X_n|\mcal{F}_n]\\
				&= \E\left[\left(\sum_{k=1}^{n+1}Y_k\right)^2 - \left(\sum_{k=1}^nY_k\right)^2 \bigg|\mcal{F}_n\right] - \sigma^2 + X_n\\
				&= \E\left[Y_{n+1}\left(2\sum_{k=1}^nY_k + Y_{n+1}\right)\bigg|\mcal{F}_n\right] - \sigma^2 + X_n\\
				&= \E[Y_{n+1}^2|\mcal{F}_n] + 2\sum_{k=1}^n\E[Y_{n+1}Y_k|\mcal{F}_n] - \sigma^2 + X_n\\
				&= \sigma^2 + 0 - \sigma^2 + X_n\quad \text{(since the }Y_k\text{'s are independent)}\\
				&= X_n.
			\end{align*}
		\end{solution}
	\end{enumerate}

	\item \begin{enumerate}
		\item Show that if $X_n\to X$ in $L^p$, $p\geq 1$, then
		\[
		X_n\to X\text{ in probability.}
		\]
		\begin{solution}
			Suppose that the random variables $X_n$ are defined on the probability space $(\Omega, \mcal{F}, \prob)$. First, we claim that if $X_n\to X$ in $L^1$. This follows from H\"older's inequality and the finiteness of $\prob(\Omega)$.
			\begin{align*}
				\int_\Omega|X_n - X|\ d\prob &\leq \Lp{X_n - X}{p}\cdot \prob(\Omega)^{1/q}\\
				&\to 0,
			\end{align*}
			where $q$ is the H\"older conjugate of $p$. Now suppose that $X_n$ didn't converge to $X$ in probability. Then for some $\epsilon>0$, there are infinitely many $n$ such that $\prob[E_n>\epsilon] > \epsilon$, where $E_n$ is the event $E_n = \{|X_n - X|>\epsilon\}$. Check this out
			\begin{align*}
				\int_\Omega|X_n - X|\ d\prob &\geq \int_{E_n}|X_n - X|\ d\prob\\
				& \int_{E_n}\epsilon\ d\prob\\
				&= \epsilon^2.
			\end{align*}
			Then $X_n$ \textit{doesn't} converge to $X$ in $L^1$. We conclude that $X_n\to X$ in probability.
		\end{solution}

		\item Construct an example with a sequence $X_n$ of random variables that converges in $L^p$, but not almost surely.
		\begin{solution}
			Consider the typewriter sequence $f_{n,k}$ given by $f_{n,k}(x) = \chi_{[k2^{-n}, (k+1)2^{-n}]}(x)$, where $n = 1, 2, \ldots$ and $k = 0, 1, \ldots 2^n-1$. Since $f_{n,k}$ is supported on a set of measure $2^{-n}$, $f_{n,k}\to 0$ in $L^1$. But $f_{n,k}(x)$ doesn't converge for any $x$, since for any fixed $n$, $f_{n,k}(x) = 1$ for some $k$. Consequently, $f_{n,k}$ doesn't converge almost surely.
		\end{solution}
	\end{enumerate}

	\item Prove that $B^2(t) - t$ is a martingale, where $B(t)$ is a standard Brownian motion.
	\begin{proof}
		Define the filtration $\mcal{F}_t = \sigma(B_s: s\leq t)$. Let's verify that $B_t^2 -t$ is integrable.
		\begin{align*}
		 	\E[|B_t^2 - t|] &\leq \E[B_t^2] + t\\
		 	&= 2t.
		\end{align*} 
		Here we've used the fact that $B_t - B_s \sim \mcal{N}(0, t-s)$. Check this out.
		\begin{align*}
			\E[B_t^2 - t| \mcal{F}_s] &= \E[(B_t - B_s + B_s)^2 - t| \mcal{F}_s]\\
			&= \E[(B_t-B_s)^2|\mcal{F}_s] + 2B_s\E[B_t-B_s|\mcal{F}_s] + B_s^2 - t\\
			&= \E[(B_t-B_s)^2] + 2B_s\E[B_t-B_s] + B_s^2 - t\quad\text{(since increments are independent)}\\
			&= (t-s) + 0 + B_s^2 - t\\
			&= B_s^2 - s.
		\end{align*}
		We conclude that $B_t^2 - t$ is a martingale.
	\end{proof}

	\item Let $W_t$ be a standard $n$-dimensional Brownian motion and fix $t_0\geq 0$. Prove that
	\[
	\tilde{W}(t) = U[W(t_0+t) - W(t_0)]:\ t\geq 0,
	\]
	is a standard $n$-dimensional Brownian motion for $U$ an orthogonal matrix.
	\begin{proof}
		Intuitively, re-centering coordinates and rotating a Brownian motion should yield another Brownian motion. $\tilde{W}$ starts at zero.
		\begin{align*}
			\tilde{W}(0) &= U[W(t_0) - W(t_0)]\\
			&= U(0)\\
			&= 0.
		\end{align*}
		$U$ is a linear transformation, so $x\mapsto Ux$ is continuous. Since $t\mapsto W(t)$ is almost surely continuous, $t\mapsto U[W(t_0+t) - W(t_0)]$ is almost surely continuous. Fix $t_1\leq t_2 \leq \cdots \leq t_m$. Since $\{W(t_k) - W(t_{k-1}): k = 1, \ldots, m\}$ are independent and $x\mapsto Ux$ is a bijection, $\{\tilde{W}(t_k) - \tilde{W}(t_{k-1})\} = \{U[W(t_k+t_0) - W(t_{k-1}+t_0)\}$ are also independent.\\

		\noindent Let $\tilde{W}^{(1)}, \ldots, \tilde{W}^{(n)}$ be the components of $\tilde{W}$. Since $W(t+t_0) - W(t_0)$ is a standard Brownian motion, the components of the increments $\tilde{W}(t) - \tilde{W}(s)$ are given by
		\[
		\tilde{W}^{(i)}(t)- \tilde{W}^{(i)}(s) = u_{i,1}\xi_1 + u_{i,2}\xi_2 + \cdots + u_{i,n}\xi_n,
		\]
		where $u_{i,j}$ is the $i,j$-th entry of $U$ and each $\xi_j$ has distribution $\mcal{N}(0, t-s)$. Since the components of $W$ are independent, so are the $\xi_k$'s. Because $U$ is an orthogonal matrix, $u_{i,1}^2 + \cdots +u_{i,n}^2 = 1$ and we have
		\begin{align*}
			\xi_j &\sim u_{i,1}\mcal{N}(0, t-s) + u_{i,2}\mcal{N}(0, t-s) + \cdots + u_{i,n}\mcal{N}(0, t-s)\\
			&= \mcal{N}(0, (u_{i,1}^2 + \cdots + u_{i,n}^2)(t-s))\\
			&= \mcal{N}(0, t-s).
		\end{align*}
		We conclude that $\tilde{W}$ is a Brownian motion.
	\end{proof}
\end{enumerate}

\end{document}